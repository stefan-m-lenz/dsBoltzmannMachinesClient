% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{ds.monitored_traindbm}
\alias{ds.monitored_traindbm}
\title{Fine-Tuning of a DBM}
\usage{
ds.monitored_traindbm(
  datasources,
  dbm = "dbm",
  newobj = "dbm",
  data = "D",
  monitoring = "logproblowerbound",
  monitoringdata = data,
  epochs = NULL,
  nparticles = NULL,
  learningrate = NULL,
  learningrates = NULL
)
}
\arguments{
\item{dbm}{The name of DBM model that is to be fine-tuned. Defaults to \code{"dbm"}.}

\item{newobj}{The name of the variable to store the new DBM model.
Defaults to \code{"dbm"}, such that the previous model is overwritten.}

\item{monitoring}{Name(s) for monitoring options used for DBM training.
For possible options, see \code{\link{ds.monitored_fitdbm}}}

\item{monitoringdata}{A vector of names of server-side data sets that are to be used for
monitoring}

\item{epochs}{Number of training epochs for fine-tuning, defaults to 10}

\item{nparticles}{Number of particles used for sampling during fine-tuning of the
DBM, defaults to 100}

\item{learningrate}{Learning rate for fine-tuning,
decaying by default decaying with the number of epochs,
starting with the given value for the \code{learningrate}.
By default, the learning rate decreases with the factor \eqn{11 / (10 + epoch)}.}

\item{learningrates}{A vector of learning rates for each epoch of fine-tuning}
}
\description{
This functions performs monitored fine-tuning of a given DBM model.
For the complete training, including the pre-training, see \code{\link{ds.monitored_fitdbm}}.
During the training, monitoring data is collected by default.
The monitoring data is returned to the user.
The trained model is stored on the server side (see parameter \code{newobj}).
}
\details{
If the option \code{dsBoltzmannMachines.shareModels} is set to \code{TRUE}
by an administrator at the server side, the model itself is returned in addition.
}
